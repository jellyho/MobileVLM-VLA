{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecb9bed-cff5-41b4-8b8f-132127b36ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 15:10:40.845613: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 15:10:40.875161: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-27 15:10:40.875203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-27 15:10:40.875936: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-27 15:10:40.881270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 15:10:41.578790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from spatialvla.mobilevlm.model.bridger.model.stochastic_interpolants import StochasticInterpolants\n",
    "from spatialvla.mobilevlm.model.bridger.model.vae import VAEModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6826c1-ee7c-429f-b003-bdd00fb107a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    \"net_type\": \"unet1D_si\",\n",
    "    \"interpolant_type\": \"power3\",\n",
    "    \"gamma_type\": \"(2t(t-1))^0.5\",\n",
    "    \"epsilon_type\": \"1-t\",\n",
    "    \"prior_policy\": \"vae\",\n",
    "    \"beta_max\": 0.03,\n",
    "    \"t0\": 1e-4,\n",
    "    \"T\": 1,\n",
    "    \"clip_denoise\": True,\n",
    "    \"pretrain\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70322b04-0890-43c2-8500-55d3fb744d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args['action_dim'] = 7\n",
    "model_args['action_horizon'] = 8\n",
    "model_args['obs_dim'] = 512\n",
    "model_args['obs_horizon'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "145b90aa-83c1-4297-9921-9db7cd9a7f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_head = StochasticInterpolants(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8daccd54-a715-432a-9aa9-10861ea09c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3.688986e+07\n",
      "number of parameters: 3.688986e+07\n",
      "number of parameters: 3.688986e+07\n"
     ]
    }
   ],
   "source": [
    "action_head.load_model(model_args, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d4cf411-d37c-4277-9595-0280223dd099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 20:58:15.426583: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-14 20:58:15.457559: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-14 20:58:15.457602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-14 20:58:15.458709: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-14 20:58:15.464174: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-14 20:58:16.155913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'else' statement on line 202 (data_utils.py, line 203)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/miniconda3/envs/mobilevlm/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[1], line 1\u001b[0m\n    from spatialvla.datasets import RLDSBatchTransform, RLDSDataset\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Bimanual_Imitation/MobileVLM-VLA/spatialvla/datasets/__init__.py:1\u001b[0m\n    from .datasets import EpisodicRLDSDataset, RLDSBatchTransform, RLDSDataset\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Bimanual_Imitation/MobileVLM-VLA/spatialvla/datasets/datasets.py:29\u001b[0m\n    from spatialvla.datasets.rlds.utils.data_utils import tree_map\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Bimanual_Imitation/MobileVLM-VLA/spatialvla/datasets/rlds/__init__.py:1\u001b[0m\n    from .dataset import make_interleaved_dataset, make_single_dataset\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Bimanual_Imitation/MobileVLM-VLA/spatialvla/datasets/rlds/dataset.py:19\u001b[0m\n    from spatialvla.datasets.rlds.utils import goal_relabeling, task_augmentation\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Bimanual_Imitation/MobileVLM-VLA/spatialvla/datasets/rlds/utils/goal_relabeling.py:12\u001b[0;36m\n\u001b[0;31m    from spatialvla.datasets.rlds.utils.data_utils import tree_merge\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/Bimanual_Imitation/MobileVLM-VLA/spatialvla/datasets/rlds/utils/data_utils.py:203\u001b[0;36m\u001b[0m\n\u001b[0;31m    path = local_path\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'else' statement on line 202\n"
     ]
    }
   ],
   "source": [
    "from spatialvla.datasets import RLDSBatchTransform, RLDSDataset\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_pretrained_vlm_for_vla, load_vla\n",
    "from scripts.spatialvla_config import ModelArguments, TrainingArguments\n",
    "import transformers\n",
    "from spatialvla.datasets.rlds.utils.data_utils import PaddedCollatorForActionPrediction\n",
    "from torch.utils.data import DataLoader\n",
    "from spatialvla.mobilevlm.action_tokenizer import ActionTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ff226-c4f9-4f12-a345-b1c10c8c3c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_args = ModelArguments()\n",
    "# model_args.use_state_input = True\n",
    "\n",
    "tokenizer, model, image_processor, _ = load_vla(\n",
    "    'checkpoints/rt1_512_16_4gpu',\n",
    "    load_8bit=False, \n",
    "    load_4bit=False,\n",
    "    device='cuda',\n",
    ")\n",
    "at = ActionTokenizer(tokenizer)\n",
    "batch_transform = RLDSBatchTransform(\n",
    "    tokenizer,\n",
    "    image_processor,\n",
    "    use_state_input=False,\n",
    "    action_tokenizer=at,\n",
    "    window_size=1,\n",
    "    future_action_window_size=7,\n",
    "    use_hz_input=False\n",
    ")\n",
    "vla_dataset = RLDSDataset(\n",
    "    data_root_dir='/data1/OXE/',\n",
    "    data_mix='bridge_oxe',\n",
    "    batch_transform=batch_transform,\n",
    "    shuffle_buffer_size=100,\n",
    "    window_size=1,\n",
    "    future_action_window_size=7,\n",
    "    use_state_input = False\n",
    ")\n",
    "\n",
    "collator = PaddedCollatorForActionPrediction(\n",
    "    tokenizer.model_max_length, \n",
    "    tokenizer.pad_token_id, \n",
    "    padding_side='right', \n",
    "    use_state_input=False,\n",
    "    use_label=True,\n",
    "    use_hz_input=False\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    vla_dataset,\n",
    "    batch_size=16,\n",
    "    sampler=None,\n",
    "    collate_fn=collator,\n",
    "    num_workers=0,  # Important =>> Set to 0 if using RLDS; TFDS rolls its own parallelism!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eefd763b-39ac-4222-9e4c-b0950930f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TrainingArguments()\n",
    "for d in dataloader:\n",
    "    batch = d\n",
    "    break\n",
    "# device_id = 0\n",
    "# input_ids=batch['input_ids'].to(device_id)\n",
    "# images=batch['pixel_values'].to(device_id)\n",
    "# attention_mask=batch['attention_mask'].to(device_id)\n",
    "# use_cache=True\n",
    "# # states=batch['proprio'].to(device_id)\n",
    "# past_key_values = None\n",
    "# labels = batch['labels'].to(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "379a33f9-c15a-454e-a849-9ce9752f170b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['hz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a30f18b-98a6-40fa-b43c-63dca0fb25c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l =[\n",
    "        (\"berkeley_autolab_ur5\", 0.019247833639383316),\n",
    "        (\"berkeley_cable_routing\", 0.002363319508731365),\n",
    "        (\"bridge\", 0.19114349782466888),\n",
    "        (\"jaco_play\", 0.004058686085045338),\n",
    "        (\"kuka\", 0.1237783432006836),\n",
    "        (\"roboturk\", 0.011293914169073105),\n",
    "        (\"rt1\", 0.45421281456947327),\n",
    "        (\"taco_extra\", 0.007307005580514669),\n",
    "        (\"taco_play\", 0.04522952809929848),\n",
    "        (\"toto\", 0.12147394567728043),\n",
    "        (\"viola\", 0.01989024691283703),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6f9450f-defe-4d33-94b3-a6f9715d226e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05253653367981315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.007307005580514669 + 0.04522952809929848"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeea7242-65f1-45d7-b92a-e71add5598db",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for i in l:\n",
    "    k += i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680eb5d4-3610-46ea-9450-9b785e052f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999991352669895"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a775b54e-0473-45ba-b070-176d63f8426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "    loss = model.forward(\n",
    "        input_ids=batch['input_ids'].to(device_id),\n",
    "        images=batch['pixel_values'].to(device_id),\n",
    "        attention_mask=batch['attention_mask'].to(device_id),\n",
    "        actions=batch['action'].to(device_id),\n",
    "        states= None,\n",
    "        labels=batch['labels'] if model.config.head_args['head_type'] == 'BR' else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bf0d483-91b2-401b-af6f-d4fdb629090c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-7.6015, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0754, device='cuda:0'),\n",
       " tensor(-3.8682, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0.0379, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-3.8466, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-7.6769, device='cuda:0', grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1edebae5-6566-4f88-8740-5af763f3d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "    action_hidden = loss.hidden_states[-1]\n",
    "    action_hidden.shape\n",
    "    condition = model.condition_projector(action_hidden)\n",
    "    prior_action = torch.tensor(at.detokenize(at.discretize(batch['action'])))\n",
    "    batch_dict = {'obs':condition, 'action':batch['action'], 'tokenized_action':prior_action}\n",
    "    loss_args = {'prior_policy':'tokenized_action'}\n",
    "    loss, loss_info = model.si.get_loss(batch_dict, loss_args, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9841f2be-d230-48e3-9ca4-189da685677e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v_loss': tensor(-6.9151, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " 's_loss': tensor(0.0423, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " 'b_loss': tensor(-6.8837, device='cuda:0', grad_fn=<MeanBackward0>)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbf759e4-e7b3-4041-a419-33cbef3d01f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m----> 2\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m      3\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mema\u001b[38;5;241m.\u001b[39mupdate()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()\n",
    "model.ema.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec4506-927d-4efc-b707-9e2223a30293",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params : {\n",
    "    \"batch_size\": 256,\n",
    "    \"num_itr\": 1501,\n",
    "    \"lr\": 5e-6,\n",
    "    \"lr_gamma\": 0.5,\n",
    "    \"lr_step\": 500,\n",
    "    \"l2_norm\": 0.0,\n",
    "    \"ema\": 0.99\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4edf3f-4332-4722-b24f-2acc7f0c2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "a = CausalLMOutputWithPast(value = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5235987-e47a-471e-84df-b2005fc161f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ed597-5c09-476f-b265-2f43dcbc6973",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "    model_actions = action_head.sample(x_prior=prior_action.cuda().to(dtype=torch.bfloat16), cond=condition.float().flatten(1), diffuse_step=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f7934a-73c1-4795-a26f-16374384d650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_actions.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
