{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e00ab5-4718-404e-9368-08feef09a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA L40S\n",
      "Using device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Restrict PyTorch to only see GPU 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU.\")\n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842a2262-3445-4f95-b729-9fa4eda679a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 19:17:31.473865: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-15 19:17:31.502986: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-15 19:17:31.503034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-15 19:17:31.503964: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-15 19:17:31.509185: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-15 19:17:34.086009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-15 19:17:44,335] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from spatialvla.datasets import RLDSBatchTransform, RLDSDataset\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_pretrained_vlm_for_vla, load_vla\n",
    "from scripts.spatialvla_config import ModelArguments, TrainingArguments\n",
    "import transformers\n",
    "from spatialvla.datasets.rlds.utils.data_utils import PaddedCollatorForActionPrediction\n",
    "from torch.utils.data import DataLoader\n",
    "from spatialvla.mobilevlm.action_tokenizer import ActionTokenizer\n",
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_vla, load_pretrained_model\n",
    "from spatialvla.mobilevlm.conversation import conv_templates, SeparatorStyle\n",
    "from spatialvla.mobilevlm.utils import disable_torch_init, process_images, tokenizer_image_token, KeywordsStoppingCriteria\n",
    "from spatialvla.mobilevlm.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple, Type\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "from spatialvla.mobilevlm.utils import disable_torch_init, process_images, tokenizer_image_token, KeywordsStoppingCriteria\n",
    "# from prismatic.models.backbones.llm.prompting import PromptBuilder\n",
    "# from prismatic.models.backbones.vision import ImageTransform\n",
    "\n",
    "from spatialvla.mobilevlm.constants import IGNORE_INDEX, IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from spatialvla.mobilevlm.conversation import conv_templates, SeparatorStyle\n",
    "from spatialvla.mobilevlm.model.bimanual import load_twinvla\n",
    "from spatialvla.datasets.rlds.utils.data_utils import tree_map\n",
    "# from prismatic.vla.action_tokenizer import ActionTokenizer\n",
    "from spatialvla.datasets.rlds import make_interleaved_dataset, make_single_dataset\n",
    "from spatialvla.datasets.rlds.oxe import OXE_NAMED_MIXTURES, get_oxe_dataset_kwargs_and_weights\n",
    "from spatialvla.datasets.rlds.utils.data_utils import NormalizationType\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f7dda9-61ac-4134-b12d-06918c27976b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyho/miniconda3/envs/mobilevlm/lib/python3.10/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/jellyho/miniconda3/envs/mobilevlm/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, image_processor, _ = load_vla('checkpoints/libero_object_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "675a5c40-9f66-4f6a-8068-fea7dc017c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'libero_object_no_noops', 'data_dir': '/home/shared/rlds_datasets', 'image_obs_keys': {'primary': 'image', 'secondary': None}, 'absolute_action_mask': [False, False, False, False, False, False, False], 'action_normalization_mask': [True, True, True, True, True, True, True], 'action_proprio_normalization_type': <NormalizationType.BOUNDS_Q99: 'bounds_q99'>, 'language_key': 'language_instruction', 'standardize_fn': <function libero_dataset_transform at 0x14b021909ea0>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 19:18:04.336577: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2025-02-15 19:18:05.196235: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################################\n",
      "# Loading the following 1 datasets (incl. sampling weight):                         #\n",
      "# libero_object_no_noops: ==================================================1.000000 #\n",
      "######################################################################################\n",
      "\n",
      "Threads per Dataset:  [1]\n",
      "Reads per Dataset:  [1]\n",
      "Constructing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 19:18:05.620964: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying frame transforms on dataset...\n"
     ]
    }
   ],
   "source": [
    "from spatialvla.mobilevlm.action_tokenizer import FASTTokenizer, ActionTokenizer\n",
    "\n",
    "fast_tokenizer = FASTTokenizer(tokenizer)\n",
    "\n",
    "batch_transform = RLDSBatchTransform(\n",
    "    tokenizer,\n",
    "    image_processor,\n",
    "    use_state_input=False,\n",
    "    window_size=1,\n",
    "    future_action_window_size=31,\n",
    "    use_hz_input=True,\n",
    "    action_tokenizer=fast_tokenizer\n",
    ")\n",
    "vla_dataset = RLDSDataset(\n",
    "    data_root_dir='/home/shared/rlds_datasets',\n",
    "    data_mix='libero_object_no_noops',\n",
    "    batch_transform=batch_transform,\n",
    "    shuffle_buffer_size=10000,\n",
    "    window_size=1,\n",
    "    future_action_window_size=31,\n",
    "    use_state_input = False,\n",
    "    quantile_norm = True\n",
    ")\n",
    "collator = PaddedCollatorForActionPrediction(\n",
    "    tokenizer.model_max_length, \n",
    "    tokenizer.pad_token_id, \n",
    "    padding_side='right', \n",
    "    use_state_input=False,\n",
    "    use_label=True,\n",
    "    use_hz_input=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7ebda6-ae8b-40e3-8bc0-d7c7f9f73cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    vla_dataset,\n",
    "    batch_size=4,\n",
    "    sampler=None,\n",
    "    collate_fn=collator,\n",
    "    num_workers=0,  # Important =>> Set to 0 if using RLDS; TFDS rolls its own parallelism!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35cfbb4e-7854-4e42-aa5b-5d9ed5c4089e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = None\n",
    "for b in dataloader:\n",
    "    batch = b\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1ab9df-8fad-437c-98be-8c2171dcf03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pixel_values', 'pixel_values_secondary', 'input_ids', 'attention_mask', 'action', 'proprio', 'hz', 'dataset_names', 'labels'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c28fc9be-49de-40be-8d79-ed41090e4ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 83])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "970e6b49-29ae-4463-9716-e78bfc1527f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85ddabe2-8306-4cde-b111-a091384f084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = batch['input_ids']\n",
    "images = batch['pixel_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e279e43-da29-41cd-882b-6b4bfa356934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialvla.inference import VLAModel\n",
    "model = VLAModel('checkpoints/libero_object_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d314daf7-d29a-4820-b9be-9d5e8732142c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spatialvla.inference.VLAModel at 0x14aac41e5c00>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference_action('libero_object_no_noops', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f58cc5cf-0b66-44cb-a407-4c3a354e9635",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StoppingCriteriaList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16):\n\u001b[1;32m      2\u001b[0m     output_ids \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m      3\u001b[0m         batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(),\n\u001b[1;32m      4\u001b[0m         images\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcuda(),\n\u001b[1;32m      5\u001b[0m         max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m      6\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m         do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m         top_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,   \n\u001b[0;32m---> 10\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39m\u001b[43mStoppingCriteriaList\u001b[49m([StopOnToken(\u001b[38;5;241m891\u001b[39m)]),  \u001b[38;5;66;03m# Add stopping criteria             \u001b[39;00m\n\u001b[1;32m     11\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StoppingCriteriaList' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "    output_ids = model.generate(\n",
    "        batch['input_ids'].cuda(),\n",
    "        images=batch['pixel_values'].cuda(),\n",
    "        max_new_tokens=128,\n",
    "        use_cache=True,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "        top_p=None,   \n",
    "        stopping_criteria=StoppingCriteriaList([StopOnToken(891)]),  # Add stopping criteria             \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6ca8c72-6149-4819-983c-d550006b820d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278, 22968, 22300,\n",
       "           322,  2058,   372,   297,   278, 25972, 29973,   319,  1799,  9047,\n",
       "         13566, 29901, 31602, 31642, 31098, 31696, 31560, 30693, 31664, 31240,\n",
       "         30944, 31704, 31362, 31720, 30471, 31725, 31583, 31712, 31155, 30901,\n",
       "         31742, 31743,   891],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278,   289, 29890,\n",
       "         29939, 12507,   346,   322,  2058,   372,   297,   278, 25972, 29973,\n",
       "           319,  1799,  9047, 13566, 29901, 31658, 31627, 31642, 31719, 31288,\n",
       "         31560, 31734, 31708, 31451, 31722, 31721, 30971, 31304, 31725, 31607,\n",
       "         31586, 31584,   891],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278,   413,  3486,\n",
       "           786,   322,  2058,   372,   297,   278, 25972, 29973,   319,  1799,\n",
       "          9047, 13566, 29901, 31148, 31705, 31678, 31705, 31691, 31560, 31559,\n",
       "         31326, 31451, 30925, 31550, 29976, 31508, 31419,   891,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278, 22968, 22300,\n",
       "           322,  2058,   372,   297,   278, 25972, 29973,   319,  1799,  9047,\n",
       "         13566, 29901, 31290, 31701, 31598, 31704, 31578, 31493, 31227, 30194,\n",
       "         31583, 31738, 31571, 31743,   891,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a718d49-c1b2-4924-8298-cb89394fce40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278, 22968, 22300,\n",
       "           322,  2058,   372,   297,   278, 25972, 29973,   319,  1799,  9047,\n",
       "         13566, 29901, 31602, 31642, 31098, 31696, 31560, 30693, 31664, 31240,\n",
       "         30944, 31704, 31362, 31720, 30471, 31725, 31583, 31712, 31155, 30901,\n",
       "         31742, 31743,   891, 31742],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278,   289, 29890,\n",
       "         29939, 12507,   346,   322,  2058,   372,   297,   278, 25972, 29973,\n",
       "           319,  1799,  9047, 13566, 29901, 31658, 31627, 31642, 31719, 31288,\n",
       "         31560, 31734, 31708, 31451, 31722, 31721, 30971, 31304, 31725, 31607,\n",
       "         31586, 31584,   891, 31739],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278,   413,  3486,\n",
       "           786,   322,  2058,   372,   297,   278, 25972, 29973,   319,  1799,\n",
       "          9047, 13566, 29901, 31148, 31705, 31678, 31705, 31691, 31560, 31559,\n",
       "         31326, 31451, 30925, 31550, 29976, 31508, 31419,   891,     0,     0,\n",
       "             0,     0,     0, 31742],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278, 22968, 22300,\n",
       "           322,  2058,   372,   297,   278, 25972, 29973,   319,  1799,  9047,\n",
       "         13566, 29901, 31290, 31701, 31598, 31704, 31578, 31493, 31227, 30194,\n",
       "         31583, 31738, 31571, 31743,   891,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,   891]], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "709138af-3698-4fba-888d-16a65ba50094",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SpatialVLAForCausalLM' object has no attribute 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_action_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpixel_values\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhzs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Bimanual_Imitation/MobileVLM-VLA/spatialvla/mobilevlm/model/mobilellama.py:477\u001b[0m, in \u001b[0;36mSpatialVLAForCausalLM.predict_action_fast\u001b[0;34m(self, input_ids, images, states, hzs, action_dim)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_action_fast\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    470\u001b[0m     input_ids: torch\u001b[38;5;241m.\u001b[39mLongTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    471\u001b[0m     images: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m ):\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# GENERATE Actions with hidden state return, take -1 index hidden state\u001b[39;00m\n\u001b[0;32m--> 477\u001b[0m     stopping_criteria \u001b[38;5;241m=\u001b[39m KeywordsStoppingCriteria([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m, input_ids)\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16):\n\u001b[1;32m    479\u001b[0m         input_length \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/mobilevlm/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SpatialVLAForCausalLM' object has no attribute 'tokenizer'"
     ]
    }
   ],
   "source": [
    "model.predict_action_fast(batch['input_ids'][0], batch['pixel_values'][0], hzs=batch['hz'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47a68135-e6c8-4761-a38d-727d5ab69bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278,  6454,  1219,\n",
       "         12507,   346,   322,  2058,   372,   297,   278, 25972, 29973,   319,\n",
       "          1799,  9047, 13566, 29901, 30644, 31648, 31629, 30240, 31560, 31221,\n",
       "         30813, 31673, 31447, 30415, 31741, 31431, 31720, 31646, 31586, 30871,\n",
       "         31604, 30296],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278, 27274,   322,\n",
       "          2058,   372,   297,   278, 25972, 29973,   319,  1799,  9047, 13566,\n",
       "         29901, 31290, 31685, 31577, 31734, 31680, 31560, 31716, 31281, 31716,\n",
       "         31709, 30471, 31712, 31613, 31448, 31725, 31586, 31583, 31739,     0,\n",
       "             0,     0],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278,   413,  3486,\n",
       "           786,   322,  2058,   372,   297,   278, 25972, 29973,   319,  1799,\n",
       "          9047, 13566, 29901, 31722, 31627, 31642, 31689, 31671, 31560, 31734,\n",
       "         31708, 30865, 31673, 30397, 31741, 31475, 31604, 31484, 31583, 31419,\n",
       "             0,     0],\n",
       "        [    1,   319, 13563,  1546,   263, 12758,  1404,   322,   385, 23116,\n",
       "         21082, 20255, 29889,   450, 20255,  4076,  8444, 29892, 13173, 29892,\n",
       "           322,  1248,   568,  6089,   304,   278,  1404, 29915, 29879,  5155,\n",
       "         29889,  3148,  1001, 29901, 29871,  -200, 29871,    13,  5618,  3158,\n",
       "           881,   278, 19964,  2125,   304,  5839,   701,   278,   907,   314,\n",
       "           923,   968,   322,  2058,   372,   297,   278, 25972, 29973,   319,\n",
       "          1799,  9047, 13566, 29901, 31610, 31600, 31658, 30454, 31578, 31708,\n",
       "         31539, 31290, 31710, 31198, 31689, 31703, 30881, 31738, 31711,     0,\n",
       "             0,     0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "895fddda-746e-4338-8461-74ae1a686690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100, 30644, 31648, 31629, 30240, 31560, 31221,\n",
       "         30813, 31673, 31447, 30415, 31741, 31431, 31720, 31646, 31586, 30871,\n",
       "         31604, 30296],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100, 31290, 31685, 31577, 31734, 31680, 31560, 31716, 31281, 31716,\n",
       "         31709, 30471, 31712, 31613, 31448, 31725, 31586, 31583, 31739,  -100,\n",
       "          -100,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100, 31722, 31627, 31642, 31689, 31671, 31560, 31734,\n",
       "         31708, 30865, 31673, 30397, 31741, 31475, 31604, 31484, 31583, 31419,\n",
       "          -100,  -100],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100, 31610, 31600, 31658, 30454, 31578, 31708,\n",
       "         31539, 31290, 31710, 31198, 31689, 31703, 30881, 31738, 31711,  -100,\n",
       "          -100,  -100]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0ea3d-33e8-43ce-8da9-928942c726b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast = AutoProcessor.from_pretrained(\"physical-intelligence/fast\", trust_remote_code=True)\n",
    "batch = None\n",
    "tokenized = []\n",
    "original = []\n",
    "list_mse = []\n",
    "count = 0\n",
    "for b in dataloader:\n",
    "    batch = b\n",
    "    action = batch['action']\n",
    "    tokens = fast(action)\n",
    "    decoded_actions = fast.decode(tokens, time_horizon=10, action_dim=7)\n",
    "    mse = ((action - decoded_actions) ** 2).mean().cpu().numpy()\n",
    "    for t in tokens:\n",
    "        tokenized.append(len(t))\n",
    "        original.append(10 * 7)\n",
    "    list_mse.append(mse)\n",
    "    count += 1\n",
    "    print(count)\n",
    "    if count == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a001a-de72-42a7-86d2-a03dac225749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d68b4282-e146-4a35-a742-4b091c91ff1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_rate = np.array(tokenized).sum() / np.array(original).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "935ec7ad-d086-48a4-80a5-6dc26b666e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24231696428571428"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1bda6b1-c925-4479-b4c8-08c61de30c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00048670708040417785"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list_mse).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba6d7f36-0882-4ccc-924c-fbdc581aafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = batch['action']\n",
    "padded_array = np.pad(action, ((0, 0), (0, 0), (0, 32 - action.shape[-1])), mode='constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84c9378c-586e-4090-aba3-ab82bd1ff9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 7])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e953b627-6f81-47e8-802e-12f3add9c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "# Load the tokenizer from the Hugging Face hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20df0ae5-f455-4110-b6d3-908f36d64b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c524a618-febd-418a-968b-52974f3a12c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c00e3e33-e5ad-4988-8434-8cc791628cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize & decode action chunks (we use dummy data here)\n",
    "tokens = fast(action)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e415249-7820-4ffa-9063-4f48902dd64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b06d896b-a2af-444b-958d-0f1bdaa7d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_actions = fast.decode(tokens, time_horizon=10, action_dim=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68fb8ce8-740a-4f98-9d7f-1d8e0b09c6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005500334909725041"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((decoded_actions[0][:, :7] - action[0].cpu().numpy())**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7681128e-f97a-4b7c-9db2-0cc4020718c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (16,15,7) (16,15,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ((\u001b[43mdecoded_actions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (16,15,7) (16,15,6) "
     ]
    }
   ],
   "source": [
    "((decoded_actions - batch['action'][:, :, :-1].cpu().numpy()) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a7696b32-25be-44a2-b210-b21291ab24db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0832,  0.3613,  0.4915, -0.4893,  0.4194,  0.0609,  1.0000],\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['action'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd87043b-dfca-4255-9e6d-9dd2d4cd68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322c224-cf21-4b72-8ff5-c26c6ca169a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
