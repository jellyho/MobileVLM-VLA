{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59dd4352-4fc4-4809-b9be-893e5a878611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA L40S\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Restrict PyTorch to only see GPU 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU.\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdfb60b-b79e-4e9e-99a6-92f9a542bdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 17:19:32.123506: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 17:19:32.153052: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 17:19:32.153097: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 17:19:32.153997: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 17:19:32.159286: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 17:19:32.798272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from spatialvla.datasets import RLDSBatchTransform, RLDSDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c3bb21-d6fa-4142-add7-412018d13a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-06 17:19:37,696] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyho/miniconda3/envs/mobilevlm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using a model of type mobilevlm to instantiate a model of type spatialvla. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of SpatialVLAForCausalLM were not initialized from the model checkpoint at remyxai/SpaceLLaVA-lite and are newly initialized: ['action_head.map_head.attention.out_proj.bias', 'action_head.map_head.attention.out_proj.weight', 'action_head.map_head.layer_norm.bias', 'action_head.map_head.mlp_block.fc2.bias', 'action_head.map_head.layer_norm.weight', 'action_head.map_head.p', 'action_head.map_head.attention.in_proj_bias', 'action_head.map_head.mlp_block.fc1.bias', 'action_head.map_head.mlp_block.fc2.weight', 'action_head.projection.weight', 'action_head.map_head.mlp_block.fc1.weight', 'action_head.map_head.attention.in_proj_weight', 'action_head.projection.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from spatialvla.mobilevlm.model.mobilevlm import load_pretrained_vlm_for_vla\n",
    "from scripts.spatialvla_config import ModelArguments, TrainingArguments\n",
    "import transformers\n",
    "\n",
    "model_args = ModelArguments()\n",
    "\n",
    "tokenizer, model, image_processor, _ = load_pretrained_vlm_for_vla(\n",
    "    model_args,\n",
    "    load_8bit=False, \n",
    "    load_4bit=False,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0b3d62-b6de-41a2-a1d2-04d1c4fa9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RLDS Dataset loading\n",
    "batch_transform = RLDSBatchTransform(\n",
    "        tokenizer,\n",
    "        image_processor,\n",
    "    )\n",
    "# Init complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a8a3efb-e5b0-4a98-a099-6452593d55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TrainingArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c0384d1-d6b3-4a5a-99fe-6baee45fe4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 17:20:17.336853: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-11-06 17:20:17.740781: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-11-06 17:20:18.391216: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-11-06 17:20:18.493089: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################################\n",
      "# Loading the following 2 datasets (incl. sampling weight):                         #\n",
      "# lg_cup_color_rightarm: ===================================================0.424252 #\n",
      "# lg_stack_cup_5hz: ========================================================0.575748 #\n",
      "######################################################################################\n",
      "\n",
      "Threads per Dataset: %s [1 1]\n",
      "Reads per Dataset: %s [1 1]\n",
      "Constructing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 17:20:18.619690: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-11-06 17:20:19.130774: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying frame transforms on dataset...\n"
     ]
    }
   ],
   "source": [
    "vla_dataset = RLDSDataset(\n",
    "        data_root_dir=cfg.data_root_dir,\n",
    "        data_mix='lg_mix',\n",
    "        batch_transform=batch_transform,\n",
    "        shuffle_buffer_size=100,\n",
    "        window_size=1,\n",
    "        future_action_window_size=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "957473c2-0df1-4fd4-b36a-613f00594b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spatialvla.datasets.rlds.utils.data_utils import PaddedCollatorForActionPrediction\n",
    "\n",
    "collator = PaddedCollatorForActionPrediction(tokenizer.model_max_length, tokenizer.pad_token_id, padding_side='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0ed2f1-c1b7-4b97-b3a2-69a463668c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(\n",
    "        vla_dataset,\n",
    "        batch_size=2,\n",
    "        sampler=None,\n",
    "        collate_fn=collator,\n",
    "        num_workers=0,  # Important =>> Set to 0 if using RLDS; TFDS rolls its own parallelism!\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b345457-5a1e-447f-989e-8b6e6e30c554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyho/Bimanual_Imitation/MobileVLM-VLA/spatialvla/datasets/datasets.py:49: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  dataset_name, action = rlds_batch[\"dataset_name\"], torch.Tensor(rlds_batch[\"action\"]).to(torch.float16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input x shape: torch.Size([2, 202, 2048])\n",
      "p shape: torch.Size([1, 1, 2048])\n",
      "torch.Size([2, 1, 2048]) 0\n",
      "After attention: out shape: torch.Size([2, 1, 2048])\n",
      "tensor([[[ 0.9770, -0.4976, -0.6277,  ...,  0.0979, -1.3399,  0.9625]],\n",
      "\n",
      "        [[ 0.9779, -0.6012, -0.5796,  ...,  0.0086, -1.3354,  1.1075]]],\n",
      "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([[[ 2.8926, -1.2119, -3.0527,  ...,  2.2441, -0.9912,  0.8364]],\n",
      "\n",
      "        [[ 2.9180, -1.4316, -3.0703,  ...,  2.0898, -0.9355,  1.2285]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device_id = 0\n",
    "for batch in dataloader:\n",
    "    with torch.autocast('cuda', dtype=torch.float16):\n",
    "        action = model.forward(\n",
    "            input_ids=batch['input_ids'].to(device_id),\n",
    "            images=batch['pixel_values'].to(device_id),\n",
    "            attention_mask=batch['attention_mask'].to(device_id)\n",
    "        )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "160d9eb1-c32d-4136-88cf-daf0ce460eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8740, -0.9097, -0.7334, -2.3711, -0.3816, -0.3276, -5.6367]],\n",
       "\n",
       "        [[ 1.7061, -0.8086, -0.6655, -2.3457, -0.3774, -0.3972, -5.6836]]],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4bd4b-0d4c-42a3-8464-e1f6f3b4f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "                                 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
