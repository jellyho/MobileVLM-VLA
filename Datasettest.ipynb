{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59dd4352-4fc4-4809-b9be-893e5a878611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA L40S\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Restrict PyTorch to only see GPU 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU.\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdfb60b-b79e-4e9e-99a6-92f9a542bdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 15:48:47.143379: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-24 15:48:47.172918: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-24 15:48:47.172960: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-24 15:48:47.173710: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-24 15:48:47.179253: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-24 15:48:47.885617: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-24 15:48:55,755] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from spatialvla.datasets import RLDSBatchTransform, RLDSDataset\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_pretrained_vlm_for_vla, load_vla\n",
    "from scripts.spatialvla_config import ModelArguments, TrainingArguments\n",
    "import transformers\n",
    "from spatialvla.datasets.rlds.utils.data_utils import PaddedCollatorForActionPrediction\n",
    "from torch.utils.data import DataLoader\n",
    "from spatialvla.mobilevlm.action_tokenizer import ActionTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24c3bb21-d6fa-4142-add7-412018d13a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading with torch.bfloat16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyho/miniconda3/envs/mobilevlm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using a model of type mobilevlm to instantiate a model of type spatialvla. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3.688986e+07\n",
      "number of parameters: 3.688986e+07\n",
      "number of parameters: 3.688986e+07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SpatialVLAForCausalLM were not initialized from the model checkpoint at remyxai/SpaceLLaVA-lite and are newly initialized: ['si.net.s_net.mid_modules.0.blocks.0.block.0.weight', 'si.net.b_net.down_modules.2.1.blocks.0.block.0.weight', 'si.net.s_net.down_modules.0.1.blocks.0.block.0.weight', 'si.net.s_net.mid_modules.1.blocks.0.block.1.bias', 'si.net.s_net.final_conv.0.block.1.weight', 'si.net.v_net.up_modules.1.1.blocks.0.block.0.weight', 'si.net.v_net.up_modules.1.1.cond_encoder.1.weight', 'condition_projector.map_head.p', 'si.net.v_net.down_modules.1.2.conv.weight', 'si.net.s_net.mid_modules.0.blocks.1.block.0.weight', 'si.net.b_net.diffusion_step_encoder.3.weight', 'si.net.b_net.down_modules.2.1.blocks.0.block.1.bias', 'si.net.s_net.up_modules.1.1.blocks.0.block.1.bias', 'si.net.b_net.down_modules.1.0.cond_encoder.1.bias', 'si.net.b_net.down_modules.0.1.blocks.1.block.0.bias', 'si.net.s_net.up_modules.1.1.cond_encoder.1.bias', 'si.net.v_net.up_modules.1.0.blocks.0.block.1.bias', 'si.net.b_net.up_modules.1.0.blocks.0.block.1.bias', 'si.net.s_net.down_modules.2.0.blocks.0.block.0.weight', 'si.net.b_net.up_modules.1.0.blocks.0.block.1.weight', 'si.net.s_net.up_modules.0.1.blocks.1.block.1.weight', 'si.net.v_net.mid_modules.0.cond_encoder.1.weight', 'si.net.b_net.diffusion_step_encoder.1.bias', 'si.net.b_net.mid_modules.0.blocks.1.block.0.bias', 'si.net.v_net.up_modules.0.1.blocks.1.block.1.bias', 'si.net.s_net.down_modules.1.2.conv.bias', 'si.net.s_net.up_modules.0.1.cond_encoder.1.weight', 'si.net.b_net.up_modules.0.0.blocks.0.block.0.bias', 'si.net.v_net.down_modules.0.0.blocks.0.block.0.bias', 'si.net.b_net.up_modules.1.0.blocks.1.block.0.weight', 'si.net.v_net.mid_modules.1.cond_encoder.1.bias', 'si.net.s_net.mid_modules.0.blocks.1.block.1.weight', 'si.net.v_net.mid_modules.1.blocks.1.block.0.weight', 'si.net.b_net.down_modules.2.0.cond_encoder.1.weight', 'si.net.v_net.up_modules.1.0.blocks.1.block.1.bias', 'si.net.v_net.down_modules.2.0.blocks.1.block.0.weight', 'si.net.s_net.down_modules.2.0.blocks.1.block.0.bias', 'si.net.s_net.down_modules.0.1.cond_encoder.1.bias', 'si.net.b_net.down_modules.2.0.blocks.0.block.0.bias', 'si.net.v_net.up_modules.0.1.blocks.0.block.1.weight', 'si.net.v_net.down_modules.0.1.blocks.1.block.0.weight', 'si.net.v_net.down_modules.1.1.blocks.1.block.0.bias', 'si.net.b_net.down_modules.0.0.blocks.0.block.1.weight', 'si.net.v_net.up_modules.1.2.conv.weight', 'si.net.v_net.down_modules.2.1.blocks.1.block.0.weight', 'si.net.b_net.mid_modules.0.blocks.1.block.0.weight', 'si.net.b_net.mid_modules.1.blocks.0.block.0.weight', 'si.net.v_net.up_modules.1.1.blocks.1.block.0.weight', 'si.net.v_net.down_modules.0.1.cond_encoder.1.bias', 'si.net.s_net.up_modules.0.0.blocks.1.block.1.bias', 'si.net.s_net.up_modules.1.0.blocks.1.block.1.weight', 'si.net.v_net.diffusion_step_encoder.1.bias', 'si.net.b_net.down_modules.0.0.blocks.0.block.0.weight', 'si.net.b_net.down_modules.2.1.blocks.1.block.1.bias', 'si.net.s_net.down_modules.1.0.blocks.1.block.0.bias', 'si.net.s_net.mid_modules.0.blocks.0.block.0.bias', 'si.net.s_net.down_modules.1.0.blocks.1.block.1.weight', 'si.net.v_net.mid_modules.1.blocks.0.block.1.weight', 'si.net.s_net.mid_modules.1.blocks.1.block.1.bias', 'si.net.b_net.up_modules.1.0.blocks.0.block.0.bias', 'si.net.v_net.up_modules.1.1.blocks.0.block.0.bias', 'si.net.v_net.down_modules.2.0.blocks.1.block.1.bias', 'condition_projector.map_head.attention.out_proj.weight', 'si.net.b_net.up_modules.1.1.blocks.0.block.0.weight', 'si.net.b_net.final_conv.1.bias', 'condition_projector.projection.weight', 'si.net.s_net.up_modules.1.0.blocks.0.block.0.bias', 'si.net.b_net.down_modules.0.0.residual_conv.weight', 'si.net.s_net.down_modules.1.1.blocks.0.block.0.bias', 'si.net.s_net.down_modules.1.0.blocks.0.block.1.bias', 'si.net.b_net.up_modules.0.1.blocks.0.block.0.weight', 'si.net.b_net.up_modules.1.1.cond_encoder.1.weight', 'si.net.v_net.down_modules.0.1.blocks.1.block.0.bias', 'si.net.b_net.up_modules.0.1.blocks.1.block.0.weight', 'si.net.v_net.mid_modules.0.blocks.0.block.0.weight', 'si.net.b_net.up_modules.1.1.cond_encoder.1.bias', 'si.net.b_net.down_modules.0.1.cond_encoder.1.bias', 'si.net.v_net.down_modules.1.2.conv.bias', 'si.net.b_net.final_conv.1.weight', 'si.net.s_net.down_modules.2.1.blocks.0.block.0.bias', 'si.net.s_net.down_modules.0.1.blocks.0.block.1.weight', 'si.net.b_net.up_modules.0.1.blocks.1.block.1.weight', 'si.net.v_net.down_modules.1.1.blocks.0.block.0.bias', 'si.net.s_net.up_modules.1.0.blocks.0.block.1.bias', 'si.net.v_net.down_modules.2.1.blocks.1.block.0.bias', 'si.net.s_net.diffusion_step_encoder.3.bias', 'si.net.b_net.down_modules.1.1.blocks.1.block.1.bias', 'si.net.s_net.down_modules.0.0.blocks.0.block.1.weight', 'si.net.v_net.down_modules.0.1.blocks.0.block.0.bias', 'si.net.s_net.mid_modules.1.blocks.0.block.1.weight', 'si.net.b_net.up_modules.0.0.blocks.1.block.1.bias', 'si.net.s_net.down_modules.1.1.blocks.0.block.1.bias', 'si.net.b_net.mid_modules.1.cond_encoder.1.weight', 'si.net.v_net.up_modules.1.0.blocks.1.block.0.weight', 'si.net.b_net.down_modules.1.0.residual_conv.bias', 'si.net.v_net.down_modules.1.1.blocks.0.block.1.weight', 'si.net.v_net.down_modules.2.1.blocks.0.block.1.weight', 'si.net.s_net.mid_modules.1.blocks.0.block.0.bias', 'si.net.s_net.down_modules.1.0.blocks.1.block.0.weight', 'si.net.s_net.up_modules.0.0.blocks.1.block.0.bias', 'si.net.v_net.down_modules.2.0.cond_encoder.1.weight', 'si.net.s_net.up_modules.0.1.blocks.1.block.1.bias', 'si.net.b_net.up_modules.0.0.blocks.0.block.1.weight', 'si.net.v_net.down_modules.0.1.blocks.1.block.1.bias', 'si.net.s_net.down_modules.0.2.conv.bias', 'si.net.b_net.up_modules.0.0.residual_conv.weight', 'si.net.b_net.down_modules.2.0.blocks.1.block.0.bias', 'si.net.v_net.up_modules.1.1.cond_encoder.1.bias', 'si.net.v_net.final_conv.1.bias', 'si.net.s_net.up_modules.1.0.blocks.1.block.1.bias', 'si.net.v_net.up_modules.1.0.blocks.1.block.1.weight', 'si.net.s_net.up_modules.1.2.conv.weight', 'si.net.b_net.down_modules.0.1.blocks.1.block.0.weight', 'si.net.b_net.down_modules.0.1.blocks.1.block.1.weight', 'si.net.s_net.up_modules.0.1.blocks.0.block.1.weight', 'si.net.s_net.down_modules.0.1.blocks.1.block.0.weight', 'si.net.v_net.up_modules.0.1.blocks.1.block.0.weight', 'si.net.s_net.down_modules.0.0.blocks.0.block.1.bias', 'si.net.s_net.down_modules.2.0.blocks.0.block.1.bias', 'si.net.v_net.diffusion_step_encoder.1.weight', 'si.net.b_net.up_modules.0.0.blocks.1.block.1.weight', 'si.net.s_net.down_modules.0.0.blocks.0.block.0.weight', 'si.net.s_net.diffusion_step_encoder.1.weight', 'si.net.v_net.down_modules.2.1.blocks.0.block.0.weight', 'si.net.v_net.down_modules.2.0.blocks.1.block.0.bias', 'si.net.b_net.down_modules.1.2.conv.weight', 'si.net.s_net.down_modules.1.1.blocks.0.block.1.weight', 'si.net.s_net.down_modules.0.0.blocks.1.block.0.bias', 'si.net.s_net.up_modules.0.2.conv.bias', 'si.net.s_net.down_modules.2.0.blocks.1.block.1.weight', 'si.net.v_net.down_modules.1.1.blocks.0.block.0.weight', 'si.net.v_net.up_modules.1.1.blocks.1.block.1.bias', 'si.net.s_net.up_modules.1.1.blocks.0.block.1.weight', 'si.net.v_net.down_modules.0.1.cond_encoder.1.weight', 'si.net.s_net.down_modules.1.0.blocks.0.block.1.weight', 'si.net.v_net.down_modules.0.0.residual_conv.bias', 'si.net.v_net.down_modules.2.1.blocks.1.block.1.bias', 'si.net.s_net.up_modules.0.0.cond_encoder.1.bias', 'si.net.s_net.down_modules.1.2.conv.weight', 'si.net.s_net.down_modules.1.0.cond_encoder.1.weight', 'si.net.v_net.mid_modules.1.blocks.1.block.1.weight', 'si.net.s_net.down_modules.1.0.residual_conv.weight', 'si.net.b_net.down_modules.1.1.blocks.1.block.0.bias', 'si.net.b_net.mid_modules.1.blocks.1.block.1.weight', 'si.net.v_net.final_conv.0.block.1.bias', 'si.net.s_net.down_modules.1.0.cond_encoder.1.bias', 'si.net.b_net.down_modules.0.1.blocks.0.block.0.weight', 'si.net.v_net.final_conv.0.block.0.weight', 'si.net.v_net.up_modules.0.0.blocks.0.block.1.weight', 'si.net.v_net.up_modules.0.1.blocks.0.block.1.bias', 'condition_projector.map_head.mlp_block.fc1.weight', 'si.net.v_net.up_modules.0.1.cond_encoder.1.bias', 'si.net.s_net.down_modules.2.1.blocks.1.block.0.weight', 'si.net.v_net.down_modules.0.2.conv.bias', 'si.net.b_net.down_modules.1.0.blocks.1.block.0.weight', 'si.net.b_net.down_modules.2.1.cond_encoder.1.weight', 'si.net.s_net.up_modules.0.0.blocks.0.block.0.bias', 'si.net.s_net.mid_modules.0.cond_encoder.1.weight', 'si.net.b_net.down_modules.1.1.blocks.1.block.0.weight', 'si.net.b_net.mid_modules.1.blocks.1.block.1.bias', 'si.net.b_net.mid_modules.0.cond_encoder.1.bias', 'si.net.b_net.down_modules.2.0.blocks.0.block.1.weight', 'si.net.s_net.up_modules.0.0.blocks.0.block.0.weight', 'si.net.s_net.down_modules.0.0.blocks.1.block.0.weight', 'si.net.b_net.up_modules.1.1.blocks.1.block.1.weight', 'si.net.b_net.mid_modules.0.blocks.0.block.0.bias', 'si.net.b_net.down_modules.1.0.blocks.0.block.0.weight', 'si.net.v_net.down_modules.1.0.blocks.0.block.0.bias', 'si.net.v_net.final_conv.0.block.0.bias', 'si.net.b_net.down_modules.1.0.blocks.0.block.1.weight', 'si.net.v_net.down_modules.2.0.blocks.1.block.1.weight', 'si.net.b_net.up_modules.0.1.cond_encoder.1.weight', 'si.net.b_net.up_modules.1.0.cond_encoder.1.bias', 'si.net.v_net.down_modules.0.0.cond_encoder.1.bias', 'si.net.b_net.final_conv.0.block.1.weight', 'si.net.v_net.down_modules.0.1.blocks.0.block.0.weight', 'condition_projector.map_head.mlp_block.fc1.bias', 'si.net.v_net.up_modules.0.1.blocks.0.block.0.weight', 'si.net.v_net.up_modules.0.0.blocks.1.block.0.weight', 'si.net.s_net.mid_modules.0.blocks.0.block.1.weight', 'si.net.b_net.down_modules.2.1.blocks.1.block.0.bias', 'si.net.v_net.down_modules.1.0.blocks.0.block.0.weight', 'si.net.b_net.up_modules.1.2.conv.weight', 'si.net.v_net.down_modules.1.0.blocks.1.block.0.bias', 'si.net.s_net.up_modules.1.0.blocks.1.block.0.bias', 'si.net.s_net.down_modules.0.0.cond_encoder.1.bias', 'si.net.b_net.down_modules.1.0.blocks.1.block.1.bias', 'si.net.v_net.down_modules.1.1.cond_encoder.1.weight', 'si.net.b_net.up_modules.0.0.cond_encoder.1.bias', 'si.net.v_net.up_modules.1.1.blocks.1.block.1.weight', 'si.net.b_net.up_modules.1.0.cond_encoder.1.weight', 'si.net.v_net.up_modules.1.0.blocks.1.block.0.bias', 'si.net.v_net.down_modules.0.0.blocks.0.block.0.weight', 'si.net.s_net.up_modules.0.1.blocks.0.block.0.bias', 'si.net.s_net.down_modules.0.1.blocks.1.block.1.bias', 'si.net.s_net.down_modules.0.0.residual_conv.bias', 'si.net.b_net.down_modules.0.1.blocks.0.block.0.bias', 'si.net.s_net.down_modules.2.0.cond_encoder.1.weight', 'si.net.s_net.final_conv.0.block.0.bias', 'si.net.b_net.mid_modules.0.blocks.0.block.1.weight', 'si.net.s_net.up_modules.0.0.blocks.0.block.1.weight', 'si.net.b_net.up_modules.0.1.blocks.0.block.1.bias', 'si.net.b_net.down_modules.2.0.blocks.0.block.1.bias', 'si.net.b_net.final_conv.0.block.1.bias', 'si.net.s_net.down_modules.1.0.residual_conv.bias', 'si.net.v_net.diffusion_step_encoder.3.weight', 'si.net.v_net.up_modules.0.2.conv.weight', 'si.net.b_net.up_modules.1.1.blocks.1.block.1.bias', 'si.net.b_net.down_modules.0.0.blocks.1.block.1.weight', 'si.net.s_net.down_modules.2.1.blocks.0.block.1.bias', 'si.net.s_net.up_modules.1.0.cond_encoder.1.weight', 'si.net.b_net.up_modules.0.0.blocks.1.block.0.bias', 'si.net.b_net.down_modules.2.0.blocks.1.block.0.weight', 'si.net.b_net.up_modules.0.0.blocks.1.block.0.weight', 'si.net.s_net.up_modules.0.0.blocks.1.block.0.weight', 'si.net.b_net.up_modules.1.0.blocks.1.block.1.bias', 'si.net.v_net.up_modules.1.0.blocks.0.block.1.weight', 'si.net.v_net.down_modules.2.1.blocks.0.block.1.bias', 'si.net.v_net.diffusion_step_encoder.3.bias', 'si.net.s_net.mid_modules.0.blocks.0.block.1.bias', 'si.net.b_net.down_modules.1.2.conv.bias', 'si.net.v_net.down_modules.0.1.blocks.0.block.1.bias', 'si.net.s_net.final_conv.0.block.1.bias', 'si.net.v_net.mid_modules.1.blocks.0.block.1.bias', 'si.net.s_net.down_modules.1.0.blocks.0.block.0.bias', 'si.net.v_net.mid_modules.1.blocks.1.block.0.bias', 'si.net.b_net.down_modules.2.1.blocks.0.block.1.weight', 'si.net.s_net.final_conv.1.bias', 'si.net.b_net.down_modules.1.1.blocks.1.block.1.weight', 'condition_projector.map_head.mlp_block.fc2.weight', 'si.net.v_net.up_modules.1.1.blocks.1.block.0.bias', 'si.net.v_net.down_modules.2.0.blocks.0.block.1.bias', 'si.net.b_net.up_modules.0.0.blocks.0.block.0.weight', 'si.net.b_net.mid_modules.1.blocks.1.block.0.weight', 'si.net.v_net.down_modules.2.0.blocks.0.block.0.bias', 'si.net.b_net.down_modules.1.0.blocks.0.block.0.bias', 'si.net.b_net.up_modules.0.1.blocks.1.block.1.bias', 'si.net.s_net.up_modules.1.1.blocks.0.block.0.bias', 'si.net.s_net.up_modules.0.0.residual_conv.bias', 'si.net.b_net.up_modules.1.0.blocks.1.block.0.bias', 'si.net.v_net.mid_modules.0.blocks.0.block.1.bias', 'si.net.v_net.down_modules.1.0.cond_encoder.1.bias', 'si.net.b_net.down_modules.1.0.blocks.1.block.1.weight', 'si.net.b_net.up_modules.0.0.blocks.0.block.1.bias', 'condition_projector.map_head.attention.out_proj.bias', 'si.net.b_net.diffusion_step_encoder.3.bias', 'si.net.s_net.down_modules.0.0.cond_encoder.1.weight', 'si.net.s_net.down_modules.0.0.residual_conv.weight', 'si.net.v_net.up_modules.0.1.blocks.1.block.0.bias', 'si.net.s_net.down_modules.1.0.blocks.1.block.1.bias', 'si.net.v_net.down_modules.2.0.blocks.0.block.0.weight', 'si.net.v_net.up_modules.0.0.cond_encoder.1.weight', 'si.net.v_net.mid_modules.0.blocks.1.block.1.bias', 'si.net.s_net.up_modules.1.1.blocks.1.block.0.bias', 'condition_projector.map_head.attention.in_proj_weight', 'condition_projector.map_head.mlp_block.fc2.bias', 'si.net.s_net.down_modules.0.1.blocks.1.block.0.bias', 'si.net.v_net.down_modules.0.2.conv.weight', 'si.net.v_net.down_modules.0.0.cond_encoder.1.weight', 'si.net.b_net.down_modules.0.1.cond_encoder.1.weight', 'si.net.v_net.up_modules.1.1.blocks.0.block.1.bias', 'si.net.s_net.down_modules.2.0.blocks.0.block.1.weight', 'si.net.b_net.down_modules.1.0.blocks.1.block.0.bias', 'si.net.b_net.up_modules.0.0.cond_encoder.1.weight', 'si.net.b_net.mid_modules.0.blocks.0.block.1.bias', 'si.net.s_net.down_modules.1.1.blocks.1.block.1.weight', 'si.net.v_net.down_modules.2.1.cond_encoder.1.bias', 'si.net.s_net.down_modules.0.0.blocks.1.block.1.weight', 'si.net.b_net.up_modules.1.1.blocks.0.block.0.bias', 'si.net.b_net.down_modules.2.1.blocks.1.block.0.weight', 'si.net.s_net.up_modules.1.1.blocks.1.block.1.bias', 'si.net.b_net.down_modules.0.0.blocks.1.block.0.weight', 'si.net.s_net.up_modules.1.1.blocks.0.block.0.weight', 'si.net.s_net.up_modules.1.0.residual_conv.bias', 'si.net.s_net.down_modules.2.1.blocks.1.block.0.bias', 'si.net.s_net.up_modules.1.1.blocks.1.block.1.weight', 'si.net.s_net.down_modules.0.1.blocks.1.block.1.weight', 'si.net.b_net.up_modules.1.1.blocks.0.block.1.bias', 'si.net.b_net.down_modules.1.0.blocks.0.block.1.bias', 'si.net.b_net.up_modules.1.1.blocks.1.block.0.weight', 'si.net.b_net.up_modules.1.0.blocks.1.block.1.weight', 'si.net.b_net.up_modules.1.0.residual_conv.bias', 'si.net.v_net.up_modules.0.0.blocks.1.block.1.bias', 'si.net.v_net.down_modules.0.0.blocks.0.block.1.bias', 'si.net.v_net.up_modules.0.0.cond_encoder.1.bias', 'si.net.v_net.down_modules.2.1.blocks.0.block.0.bias', 'si.net.b_net.up_modules.0.1.blocks.0.block.1.weight', 'si.net.v_net.down_modules.0.1.blocks.1.block.1.weight', 'si.net.v_net.up_modules.0.0.blocks.0.block.0.weight', 'si.net.s_net.down_modules.0.1.blocks.0.block.0.bias', 'condition_projector.map_head.attention.in_proj_bias', 'si.net.v_net.down_modules.0.0.blocks.1.block.1.bias', 'si.net.b_net.mid_modules.0.blocks.1.block.1.bias', 'si.net.b_net.down_modules.2.1.blocks.1.block.1.weight', 'si.net.s_net.up_modules.1.1.cond_encoder.1.weight', 'si.net.b_net.down_modules.0.0.blocks.0.block.0.bias', 'si.net.v_net.down_modules.2.0.blocks.0.block.1.weight', 'si.net.v_net.mid_modules.0.blocks.1.block.1.weight', 'si.net.s_net.down_modules.1.0.blocks.0.block.0.weight', 'si.net.s_net.final_conv.1.weight', 'si.net.s_net.down_modules.2.1.blocks.0.block.0.weight', 'si.net.v_net.down_modules.1.0.blocks.1.block.0.weight', 'si.net.s_net.mid_modules.1.blocks.1.block.1.weight', 'si.net.s_net.down_modules.2.1.blocks.0.block.1.weight', 'si.net.s_net.mid_modules.0.cond_encoder.1.bias', 'si.net.v_net.up_modules.1.2.conv.bias', 'si.net.v_net.down_modules.1.1.blocks.0.block.1.bias', 'si.net.s_net.up_modules.0.0.residual_conv.weight', 'si.net.s_net.up_modules.1.0.cond_encoder.1.bias', 'si.net.v_net.up_modules.1.0.cond_encoder.1.weight', 'si.net.s_net.mid_modules.1.cond_encoder.1.bias', 'si.net.v_net.up_modules.1.0.blocks.0.block.0.weight', 'si.net.b_net.down_modules.0.0.blocks.0.block.1.bias', 'si.net.v_net.down_modules.1.1.blocks.1.block.0.weight', 'si.net.b_net.up_modules.1.1.blocks.0.block.1.weight', 'si.net.b_net.up_modules.0.1.cond_encoder.1.bias', 'si.net.b_net.mid_modules.1.blocks.1.block.0.bias', 'si.net.b_net.down_modules.2.0.cond_encoder.1.bias', 'si.net.b_net.down_modules.0.0.cond_encoder.1.bias', 'si.net.b_net.mid_modules.1.blocks.0.block.1.bias', 'si.net.s_net.final_conv.0.block.0.weight', 'si.net.s_net.up_modules.0.1.blocks.1.block.0.bias', 'si.net.b_net.up_modules.0.1.blocks.0.block.0.bias', 'si.net.v_net.up_modules.0.0.residual_conv.weight', 'si.net.v_net.down_modules.0.0.blocks.1.block.1.weight', 'si.net.s_net.down_modules.1.1.cond_encoder.1.weight', 'si.net.s_net.mid_modules.1.blocks.1.block.0.bias', 'si.net.v_net.up_modules.0.1.blocks.1.block.1.weight', 'si.net.b_net.mid_modules.0.blocks.1.block.1.weight', 'si.net.v_net.down_modules.1.0.residual_conv.weight', 'si.net.s_net.up_modules.1.0.blocks.1.block.0.weight', 'si.net.s_net.up_modules.0.1.blocks.0.block.1.bias', 'si.net.v_net.down_modules.0.0.blocks.0.block.1.weight', 'si.net.b_net.down_modules.1.1.cond_encoder.1.weight', 'si.net.v_net.up_modules.0.2.conv.bias', 'si.net.s_net.up_modules.0.0.blocks.0.block.1.bias', 'si.net.v_net.down_modules.1.0.blocks.0.block.1.weight', 'condition_projector.projection.bias', 'si.net.b_net.up_modules.0.2.conv.weight', 'condition_projector.map_head.layer_norm.weight', 'si.net.s_net.mid_modules.0.blocks.1.block.0.bias', 'si.net.b_net.down_modules.0.1.blocks.0.block.1.bias', 'si.net.v_net.up_modules.0.0.blocks.1.block.0.bias', 'si.net.s_net.up_modules.0.1.blocks.0.block.0.weight', 'si.net.s_net.diffusion_step_encoder.1.bias', 'si.net.s_net.mid_modules.1.blocks.1.block.0.weight', 'si.net.s_net.mid_modules.0.blocks.1.block.1.bias', 'si.net.v_net.up_modules.0.0.blocks.0.block.1.bias', 'si.net.v_net.mid_modules.0.blocks.1.block.0.bias', 'si.net.s_net.mid_modules.1.cond_encoder.1.weight', 'si.net.s_net.down_modules.2.1.blocks.1.block.1.weight', 'si.net.b_net.down_modules.0.0.cond_encoder.1.weight', 'si.net.v_net.down_modules.1.1.blocks.1.block.1.bias', 'si.net.s_net.up_modules.1.0.blocks.0.block.1.weight', 'si.net.b_net.mid_modules.1.blocks.0.block.0.bias', 'si.net.s_net.down_modules.1.1.blocks.0.block.0.weight', 'si.net.s_net.down_modules.2.1.cond_encoder.1.weight', 'si.net.v_net.down_modules.1.0.blocks.1.block.1.bias', 'si.net.v_net.up_modules.1.1.blocks.0.block.1.weight', 'si.net.v_net.down_modules.2.0.cond_encoder.1.bias', 'si.net.v_net.final_conv.0.block.1.weight', 'si.net.s_net.down_modules.1.1.blocks.1.block.0.weight', 'si.net.b_net.down_modules.0.2.conv.weight', 'si.net.b_net.up_modules.1.0.blocks.0.block.0.weight', 'si.net.v_net.down_modules.0.1.blocks.0.block.1.weight', 'si.net.b_net.mid_modules.1.cond_encoder.1.bias', 'si.net.b_net.mid_modules.1.blocks.0.block.1.weight', 'si.net.v_net.up_modules.0.1.cond_encoder.1.weight', 'si.net.v_net.mid_modules.0.cond_encoder.1.bias', 'si.net.s_net.up_modules.0.0.blocks.1.block.1.weight', 'si.net.v_net.down_modules.1.1.cond_encoder.1.bias', 'si.net.v_net.down_modules.0.0.blocks.1.block.0.weight', 'si.net.s_net.down_modules.1.1.blocks.1.block.1.bias', 'si.net.b_net.up_modules.0.2.conv.bias', 'si.net.b_net.up_modules.1.2.conv.bias', 'si.net.b_net.up_modules.0.1.blocks.1.block.0.bias', 'si.net.v_net.up_modules.0.0.blocks.1.block.1.weight', 'si.net.s_net.diffusion_step_encoder.3.weight', 'si.net.v_net.up_modules.0.0.residual_conv.bias', 'si.net.b_net.down_modules.1.1.cond_encoder.1.bias', 'si.net.s_net.up_modules.1.0.blocks.0.block.0.weight', 'si.net.v_net.up_modules.1.0.residual_conv.bias', 'si.net.b_net.down_modules.2.1.blocks.0.block.0.bias', 'si.net.s_net.down_modules.0.1.cond_encoder.1.weight', 'si.net.b_net.down_modules.2.0.blocks.0.block.0.weight', 'si.net.b_net.down_modules.1.1.blocks.0.block.0.weight', 'si.net.v_net.final_conv.1.weight', 'si.net.v_net.down_modules.2.1.cond_encoder.1.weight', 'si.net.v_net.up_modules.1.0.cond_encoder.1.bias', 'si.net.b_net.mid_modules.0.cond_encoder.1.weight', 'si.net.s_net.up_modules.1.2.conv.bias', 'si.net.s_net.down_modules.2.0.blocks.1.block.0.weight', 'si.net.b_net.down_modules.2.0.blocks.1.block.1.weight', 'si.net.b_net.down_modules.2.1.cond_encoder.1.bias', 'si.net.s_net.up_modules.0.1.blocks.1.block.0.weight', 'si.net.b_net.final_conv.0.block.0.bias', 'si.net.b_net.down_modules.1.0.residual_conv.weight', 'si.net.v_net.down_modules.0.0.residual_conv.weight', 'si.net.s_net.down_modules.2.1.blocks.1.block.1.bias', 'si.net.b_net.final_conv.0.block.0.weight', 'si.net.b_net.diffusion_step_encoder.1.weight', 'si.net.s_net.up_modules.0.1.cond_encoder.1.bias', 'si.net.b_net.down_modules.0.1.blocks.1.block.1.bias', 'si.net.v_net.mid_modules.0.blocks.0.block.1.weight', 'si.net.s_net.down_modules.2.0.blocks.0.block.0.bias', 'si.net.s_net.down_modules.0.0.blocks.0.block.0.bias', 'si.net.s_net.down_modules.2.1.cond_encoder.1.bias', 'si.net.b_net.down_modules.0.1.blocks.0.block.1.weight', 'si.net.v_net.mid_modules.1.cond_encoder.1.weight', 'si.net.b_net.mid_modules.0.blocks.0.block.0.weight', 'si.net.v_net.down_modules.1.0.blocks.0.block.1.bias', 'si.net.v_net.down_modules.1.0.cond_encoder.1.weight', 'si.net.v_net.down_modules.2.1.blocks.1.block.1.weight', 'si.net.s_net.down_modules.1.1.cond_encoder.1.bias', 'si.net.v_net.up_modules.0.1.blocks.0.block.0.bias', 'si.net.b_net.down_modules.1.1.blocks.0.block.0.bias', 'si.net.b_net.up_modules.0.0.residual_conv.bias', 'si.net.s_net.up_modules.0.2.conv.weight', 'si.net.v_net.up_modules.0.0.blocks.0.block.0.bias', 'si.net.v_net.down_modules.0.0.blocks.1.block.0.bias', 'si.net.v_net.mid_modules.1.blocks.0.block.0.bias', 'si.net.b_net.up_modules.1.0.residual_conv.weight', 'si.net.b_net.down_modules.1.1.blocks.0.block.1.bias', 'si.net.s_net.down_modules.2.0.blocks.1.block.1.bias', 'si.net.b_net.down_modules.0.0.residual_conv.bias', 'si.net.s_net.down_modules.0.2.conv.weight', 'si.net.b_net.down_modules.0.0.blocks.1.block.1.bias', 'si.net.s_net.up_modules.0.0.cond_encoder.1.weight', 'si.net.s_net.up_modules.1.1.blocks.1.block.0.weight', 'si.net.s_net.down_modules.1.1.blocks.1.block.0.bias', 'si.net.v_net.down_modules.1.0.blocks.1.block.1.weight', 'si.net.v_net.up_modules.1.0.residual_conv.weight', 'condition_projector.map_head.layer_norm.bias', 'si.net.b_net.down_modules.1.1.blocks.0.block.1.weight', 'si.net.b_net.down_modules.2.0.blocks.1.block.1.bias', 'si.net.b_net.down_modules.0.2.conv.bias', 'si.net.s_net.down_modules.0.1.blocks.0.block.1.bias', 'si.net.s_net.down_modules.2.0.cond_encoder.1.bias', 'si.net.v_net.mid_modules.0.blocks.0.block.0.bias', 'si.net.v_net.down_modules.1.0.residual_conv.bias', 'si.net.v_net.up_modules.1.0.blocks.0.block.0.bias', 'si.net.s_net.down_modules.0.0.blocks.1.block.1.bias', 'si.net.s_net.mid_modules.1.blocks.0.block.0.weight', 'si.net.v_net.down_modules.1.1.blocks.1.block.1.weight', 'si.net.v_net.mid_modules.1.blocks.0.block.0.weight', 'si.net.b_net.down_modules.0.0.blocks.1.block.0.bias', 'si.net.b_net.up_modules.1.1.blocks.1.block.0.bias', 'si.net.b_net.down_modules.1.0.cond_encoder.1.weight', 'si.net.s_net.up_modules.1.0.residual_conv.weight', 'si.net.v_net.mid_modules.1.blocks.1.block.1.bias', 'si.net.v_net.mid_modules.0.blocks.1.block.0.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'bm_pick_tape_single', 'data_dir': '/home/shared/vla_benchmark_rlds', 'image_obs_keys': {'primary': 'image'}, 'absolute_action_mask': [False, False, False, False, False, False, True], 'action_normalization_mask': [True, True, True, True, True, True, False], 'action_proprio_normalization_type': <NormalizationType.NORMAL: 'normal'>, 'language_key': 'language_instruction', 'standardize_fn': <function lg_delta_ee_transform at 0x14b13637beb0>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 15:49:13.779675: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n",
      "2024-12-24 15:49:14.506331: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################################\n",
      "# Loading the following 1 datasets (incl. sampling weight):                         #\n",
      "# bm_pick_tape_single: =====================================================1.000000 #\n",
      "######################################################################################\n",
      "\n",
      "Threads per Dataset:  [1]\n",
      "Reads per Dataset:  [1]\n",
      "Constructing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-24 15:49:14.923645: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying frame transforms on dataset...\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArguments()\n",
    "# model_args.use_state_input = True\n",
    "\n",
    "# tokenizer, model, image_processor, _ = load_vla(\n",
    "#     'checkpoints/pick_tape_single_br_v7_ema',\n",
    "#     load_8bit=False, \n",
    "#     load_4bit=False,\n",
    "#     device='cuda',\n",
    "# )\n",
    "\n",
    "tokenizer, model, image_processor, _ = load_pretrained_vlm_for_vla(\n",
    "    model_args, \n",
    "    load_8bit=False, \n",
    "    load_4bit=False,\n",
    "    device='cuda',\n",
    "    dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "at = ActionTokenizer(tokenizer)\n",
    "\n",
    "batch_transform = RLDSBatchTransform(\n",
    "    tokenizer,\n",
    "    image_processor,\n",
    "    use_state_input=False,\n",
    "    action_tokenizer=at,\n",
    "    window_size=1,\n",
    "    future_action_window_size=7,\n",
    ")\n",
    "vla_dataset = RLDSDataset(\n",
    "    data_root_dir='/home/shared/vla_benchmark_rlds',\n",
    "    data_mix='bm_pick_tape_single',\n",
    "    batch_transform=batch_transform,\n",
    "    shuffle_buffer_size=100,\n",
    "    window_size=1,\n",
    "    future_action_window_size=7,\n",
    "    train=True,\n",
    "    use_state_input = False\n",
    ")\n",
    "\n",
    "collator = PaddedCollatorForActionPrediction(\n",
    "    tokenizer.model_max_length, \n",
    "    tokenizer.pad_token_id, \n",
    "    padding_side='right', \n",
    "    use_state_input=False,\n",
    "    use_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eddaff12-42cb-45c4-8be2-c3cc5767276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in model.state_dict().keys():\n",
    "    if 'ema' in k:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d7c74f-5b06-4b5c-a0f4-56e1c374b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    vla_dataset,\n",
    "    batch_size=16,\n",
    "    sampler=None,\n",
    "    collate_fn=collator,\n",
    "    num_workers=0,  # Important =>> Set to 0 if using RLDS; TFDS rolls its own parallelism!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a8a3efb-e5b0-4a98-a099-6452593d55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TrainingArguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd2ae124-0031-4dad-bdbc-4c6032033e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataloader:\n",
    "    batch = d\n",
    "    break\n",
    "device_id = 0\n",
    "input_ids=batch['input_ids'].to(device_id)\n",
    "images=batch['pixel_values'].to(device_id)\n",
    "attention_mask=batch['attention_mask'].to(device_id)\n",
    "actionss=batch['action'].to(device_id)\n",
    "use_cache=True\n",
    "# states=batch['proprio'].to(device_id)\n",
    "past_key_values = None\n",
    "labels = batch['labels'].to(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5d1b74d-ee87-4cf1-989d-33f1b347c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "    loss = model.forward(\n",
    "        input_ids=batch['input_ids'].to(device_id),\n",
    "        images=batch['pixel_values'].to(device_id),\n",
    "        attention_mask=batch['attention_mask'].to(device_id),\n",
    "        actions=batch['action'].to(device_id),\n",
    "        states=None,\n",
    "        labels=batch['labels'] if model.config.head_args['head_type'] == 'BR' else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "468faf4d-2b65-4482-b656-6ec04dfb0509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.2192, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor(0.0812, device='cuda:0'),\n",
       " tensor(-22.8653, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-23.1423, device='cuda:0', grad_fn=<MeanBackward0>),\n",
       " tensor(-46.0073, device='cuda:0', grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9432add-a941-4bdf-a006-764c58ebdf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import argparse\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_vla, load_pretrained_model\n",
    "from spatialvla.mobilevlm.conversation import conv_templates, SeparatorStyle\n",
    "from spatialvla.mobilevlm.utils import disable_torch_init, process_images, tokenizer_image_token, KeywordsStoppingCriteria\n",
    "from spatialvla.mobilevlm.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a623731-50d6-4872-9eb0-2bb9e20d5b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Tuple, Type\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "\n",
    "from transformers import PreTrainedTokenizerBase\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "from spatialvla.mobilevlm.utils import disable_torch_init, process_images, tokenizer_image_token, KeywordsStoppingCriteria\n",
    "# from prismatic.models.backbones.llm.prompting import PromptBuilder\n",
    "# from prismatic.models.backbones.vision import ImageTransform\n",
    "\n",
    "from spatialvla.mobilevlm.constants import IGNORE_INDEX, IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from spatialvla.mobilevlm.conversation import conv_templates, SeparatorStyle\n",
    "\n",
    "from spatialvla.datasets.rlds.utils.data_utils import tree_map\n",
    "# from prismatic.vla.action_tokenizer import ActionTokenizer\n",
    "from spatialvla.datasets.rlds import make_interleaved_dataset, make_single_dataset\n",
    "from spatialvla.datasets.rlds.oxe import OXE_NAMED_MIXTURES, get_oxe_dataset_kwargs_and_weights\n",
    "from spatialvla.datasets.rlds.utils.data_utils import NormalizationType\n",
    "from transformers import PreTrainedTokenizerBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0987e44b-5399-4ad9-8ebb-4c2ef83d3bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64]) torch.Size([16, 64]) None torch.Size([16, 1, 3, 336, 336])\n",
      "torch.Size([16, 65]) torch.Size([16, 65]) None torch.Size([16, 1, 3, 336, 336])\n",
      "torch.Size([16, 66]) torch.Size([16, 66]) None torch.Size([16, 1, 3, 336, 336])\n",
      "torch.Size([16, 67]) torch.Size([16, 67]) None torch.Size([16, 1, 3, 336, 336])\n",
      "torch.Size([16, 68]) torch.Size([16, 68]) None torch.Size([16, 1, 3, 336, 336])\n",
      "torch.Size([16, 69]) torch.Size([16, 69]) None torch.Size([16, 1, 3, 336, 336])\n",
      "torch.Size([16, 70]) torch.Size([16, 70]) None torch.Size([16, 1, 3, 336, 336])\n",
      "torch.Size([16, 71]) torch.Size([16, 71]) None torch.Size([16, 1, 3, 336, 336])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        actions_br = model.predict_action_br(\n",
    "            input_ids=input_ids[:, :-8],\n",
    "            images=images[:],\n",
    "            num_denoise_steps=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12792931-9073-440e-ad46-f79f014a575d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8740, device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "nn.functional.mse_loss(actionss, actions_br, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3bed663-0fcf-4521-b88f-a5701979b131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5019, -0.7926, -1.8367, -0.1677,  0.2403, -1.0333,  0.2909],\n",
       "        [ 1.6887,  0.2262, -1.9474,  0.4048,  0.4033, -0.8842,  0.4572],\n",
       "        [ 1.9272,  0.6293, -1.9488,  0.0117,  0.5113, -0.9435,  0.2222],\n",
       "        [ 1.4732,  0.5903, -1.9944, -1.1992, -0.1808, -1.9376,  0.9984],\n",
       "        [ 2.3378,  0.1889, -1.1431, -1.1910, -0.1030, -0.7218,  0.2110],\n",
       "        [ 1.1323,  0.1495, -1.6374, -0.4839, -1.4024, -1.4258,  0.6771],\n",
       "        [ 1.7719, -0.0337,  0.0914, -0.6590, -1.5853, -0.7280,  0.5479],\n",
       "        [ 0.1736, -0.0557, -1.1310,  0.1668, -1.5495, -1.4959,  0.7174]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_br[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9465f946-4964-4944-9249-220d2dc55b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3622, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.mse_loss(actions_br[1], actionss[1], reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "659651a0-bd43-46b9-a8b9-4d49bc930469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9945, device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(sum((actions_br - actionss[0:3]) ** 2)))/(3 * 7 * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c595a39-2dc6-49c0-bcb5-17083ac7d9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_action = torch.tensor(at.detokenize(input_ids[0:3, -8:].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfb509ed-5d07-40c1-861b-0b7ca1819339",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        actions = model.predict_action(\n",
    "            input_ids=input_ids[0:3],\n",
    "            images=images[0:3],\n",
    "            prior_actions=prior_action,\n",
    "        )\n",
    "    \n",
    "# condition = model.condition_projector(action_hidden)\n",
    "# predicted_action = model.si.sample(\n",
    "#     x_prior=prior_action.cuda().to(dtype=torch.bfloat16),\n",
    "#     cond=condition.float().flatten(1),\n",
    "#     diffuse_step=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e48cf40-ccce-48d1-88b0-70295783b651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0144e+00,  3.4179e-01,  7.2654e-01,  3.9015e-01, -9.3770e-01,\n",
       "          -4.5149e-01, -7.6228e-01],\n",
       "         [ 2.0379e+00,  8.4566e-01,  9.0550e-02, -8.2488e-01, -1.2245e+00,\n",
       "          -6.4813e-01, -6.4755e-02],\n",
       "         [ 8.8245e-01,  8.7198e-02,  4.4365e-01, -2.2315e-01, -1.5250e+00,\n",
       "          -4.1966e-01, -4.1730e-01],\n",
       "         [ 1.3478e+00,  8.5450e-01,  1.0696e+00, -8.3486e-01, -1.7778e-01,\n",
       "          -2.8512e-01, -8.4387e-01],\n",
       "         [ 1.1205e+00,  1.0850e-01,  6.1234e-01, -1.0628e+00, -1.1799e+00,\n",
       "          -4.9026e-01, -5.8264e-01],\n",
       "         [ 1.3364e+00,  1.9319e+00,  1.2419e+00, -8.2427e-01, -9.5564e-02,\n",
       "          -8.9882e-01, -4.8563e-01],\n",
       "         [ 6.5008e-01,  1.5054e+00,  1.4593e+00, -1.1284e+00, -4.1123e-01,\n",
       "          -1.5325e-01, -4.8267e-01],\n",
       "         [ 9.0568e-01,  1.9906e+00,  1.4715e+00, -1.0812e+00,  3.9649e-04,\n",
       "          -3.5556e-01, -7.1115e-01]],\n",
       "\n",
       "        [[-1.3972e+00,  5.5643e-01, -9.5746e-01,  3.8262e-01, -8.7173e-01,\n",
       "          -3.8574e-01,  4.7621e-01],\n",
       "         [-5.6047e-01,  1.9633e-01, -1.5296e+00, -7.8944e-02, -9.6177e-01,\n",
       "          -2.0997e-01,  1.0995e+00],\n",
       "         [-1.1855e+00,  1.0973e-01, -8.5225e-01,  1.6100e-01, -7.4583e-01,\n",
       "          -9.3742e-01,  6.9915e-01],\n",
       "         [-5.4423e-01,  6.6443e-01, -1.2738e+00, -6.7833e-02, -3.7574e-01,\n",
       "          -3.2492e-01, -5.7841e-01],\n",
       "         [-1.1667e+00,  2.8356e-01, -1.6832e+00,  3.4011e-01, -9.6947e-01,\n",
       "          -4.9770e-01, -5.5209e-01],\n",
       "         [-4.4058e-01, -5.0579e-01, -1.0637e+00,  5.4880e-01, -3.9574e-01,\n",
       "          -5.2139e-01, -2.0701e-01],\n",
       "         [-6.9887e-01, -7.0929e-01, -8.7549e-01, -1.0661e-02, -9.1293e-01,\n",
       "          -4.9329e-02, -5.0756e-01],\n",
       "         [-7.9984e-01, -5.4851e-01, -8.1917e-01,  1.9620e-01, -2.2883e-01,\n",
       "          -5.0310e-02, -5.4499e-01]],\n",
       "\n",
       "        [[ 9.1325e-01,  5.1723e-01, -1.6128e-01,  4.8438e-01, -8.2418e-01,\n",
       "          -4.2197e-01, -5.3295e-01],\n",
       "         [ 1.8305e+00,  5.5784e-01, -5.3332e-02, -7.4046e-01, -1.1511e+00,\n",
       "          -3.0300e-01,  2.4176e-01],\n",
       "         [ 9.6141e-01,  2.8252e-01,  7.3431e-01, -1.4230e-01, -1.6141e+00,\n",
       "          -6.1707e-01, -3.6846e-01],\n",
       "         [ 1.3332e+00,  6.9280e-01,  8.8839e-01,  2.2739e-01, -1.1438e+00,\n",
       "           6.6498e-03, -8.2833e-01],\n",
       "         [ 8.0429e-01,  4.9359e-01,  5.5714e-01,  2.3485e-01, -2.2075e+00,\n",
       "          -5.0562e-01, -4.5380e-01],\n",
       "         [ 1.4346e+00,  9.5631e-01,  1.3264e+00,  5.9037e-01, -1.1884e+00,\n",
       "          -7.1927e-01, -3.1312e-01],\n",
       "         [ 5.9379e-01,  5.9931e-01,  1.3076e+00, -1.0108e+00, -4.8619e-01,\n",
       "          -9.8449e-02, -3.6603e-01],\n",
       "         [ 8.9768e-01,  7.7384e-01,  1.1983e+00, -1.0478e+00, -5.8874e-02,\n",
       "          -2.5164e-01, -6.9157e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59576a8f-2c56-4bff-859b-c0c6cf4a0397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2844, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for d in dataloader:\n",
    "    batch = d\n",
    "    break\n",
    "device_id = 0\n",
    "input_ids=batch['input_ids'].to(device_id)\n",
    "images=batch['pixel_values'].to(device_id)\n",
    "attention_mask=batch['attention_mask'].to(device_id)\n",
    "actionss=batch['action'].to(device_id)\n",
    "use_cache=True\n",
    "# states=batch['proprio'].to(device_id)\n",
    "past_key_values = None\n",
    "labels = batch['labels'].to(device_id)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    with torch.autocast('cuda', dtype=torch.bfloat16):\n",
    "        loss = model.forward(\n",
    "                input_ids=batch['input_ids'].to(device_id),\n",
    "                images=batch['pixel_values'].to(device_id),\n",
    "                attention_mask=batch['attention_mask'].to(device_id),\n",
    "                actions=batch['action'].to(device_id),\n",
    "                states=batch['proprio'] if model_args.use_state_input else None,\n",
    "                labels=batch['labels'] if model.config.head_args['head_type'] == 'BR' else None\n",
    "        )\n",
    "loss.loss[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f17ab02-44ed-4d5a-9906-b5e9c6f109be",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_logits = loss.logits[:, -51:-1]\n",
    "action_preds = action_logits.argmax(dim=2)\n",
    "action_gt = batch['labels'][:, -50:].to(action_logits.device)\n",
    "mask = action_gt > at.action_token_begin_idx\n",
    "correct_preds = (action_preds == action_gt) & mask\n",
    "action_accuracy = correct_preds.sum().float() / mask.sum().float()\n",
    "eps_loss = loss.loss[5]\n",
    "v_loss = loss.loss[2]\n",
    "s_loss = loss.loss[3]\n",
    "b_loss = loss.loss[4]\n",
    "tot_loss = loss.loss[0]\n",
    "ce_loss = loss.loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5c816a1-9455-453d-ac70-d5c4c38b4660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2844, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fcfcf13-7712-47d4-9caf-3a0dbe62a950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29878, 30992, 31223, 31223, 31141, 31114, 31033, 31033],\n",
       "        [30053, 30053, 30053, 30053, 30053, 30052, 29971, 29970],\n",
       "        [29878, 31223, 31223, 31141, 31114, 31033, 31033, 31060],\n",
       "        [29880, 29881, 29880, 29853, 29853, 29854, 30190, 30163],\n",
       "        [31060, 31060, 31060, 31060, 31060, 31060, 31060, 31030],\n",
       "        [ 4989, 31030, 31111, 31111, 31138, 31138, 31139, 31139],\n",
       "        [29890, 29961, 29961, 29880, 29880, 29880, 29880, 29880],\n",
       "        [29999, 30268, 30025, 30025, 30025, 30025, 30026, 30026],\n",
       "        [29881, 30974, 30992, 31223, 31223, 31141, 31114, 31033],\n",
       "        [29926, 29853, 29853, 29854, 30190, 30163, 30163, 30244],\n",
       "        [29890, 29961, 29961, 29961, 29880, 29880, 29880, 29880],\n",
       "        [29880, 29880, 29880, 29880, 29880, 29880, 29881, 29881],\n",
       "        [29872, 30190, 30163, 30163, 30244, 30245, 30974, 30974],\n",
       "        [29853, 30432, 30432, 30189, 30270, 30267, 30267, 30268],\n",
       "        [29881, 29881, 29881, 29880, 29853, 29853, 29854, 30190],\n",
       "        [29881, 29880, 29880, 29881, 29881, 29881, 29881, 29880]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_preds[:, -8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54d2e924-d865-4bba-94e2-350b0f1925f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30974, 30992, 31223, 31223, 31141, 31114, 31033, 31033],\n",
       "        [30026, 30053, 30053, 30053, 30053, 30052, 29971, 29970],\n",
       "        [30992, 31223, 31223, 31141, 31114, 31033, 31033, 31060],\n",
       "        [29881, 29881, 29880, 29853, 29853, 29854, 30190, 30163],\n",
       "        [31060, 31060, 31060, 31060, 31060, 31060, 31060, 31030],\n",
       "        [31030, 31030, 31111, 31111, 31138, 31138, 31139, 31139],\n",
       "        [29961, 29961, 29961, 29880, 29880, 29880, 29880, 29880],\n",
       "        [30267, 30268, 30025, 30025, 30025, 30025, 30026, 30026],\n",
       "        [30974, 30974, 30992, 31223, 31223, 31141, 31114, 31033],\n",
       "        [29880, 29853, 29853, 29854, 30190, 30163, 30163, 30244],\n",
       "        [29961, 29961, 29961, 29961, 29880, 29880, 29880, 29880],\n",
       "        [29880, 29880, 29880, 29880, 29880, 29880, 29881, 29881],\n",
       "        [29854, 30190, 30163, 30163, 30244, 30245, 30974, 30974],\n",
       "        [30432, 30432, 30432, 30189, 30270, 30267, 30267, 30268],\n",
       "        [29881, 29881, 29881, 29880, 29853, 29853, 29854, 30190],\n",
       "        [29880, 29880, 29880, 29881, 29881, 29881, 29881, 29880]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_gt[:, -8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bd9b9df-1709-4578-888c-280c2b69843a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[30974, 30992, 31223, 31223, 31141, 31114, 31033, 31033],\n",
       "        [30026, 30053, 30053, 30053, 30053, 30052, 29971, 29970],\n",
       "        [30992, 31223, 31223, 31141, 31114, 31033, 31033, 31060],\n",
       "        [29881, 29881, 29880, 29853, 29853, 29854, 30190, 30163],\n",
       "        [31060, 31060, 31060, 31060, 31060, 31060, 31060, 31030],\n",
       "        [31030, 31030, 31111, 31111, 31138, 31138, 31139, 31139],\n",
       "        [29961, 29961, 29961, 29880, 29880, 29880, 29880, 29880],\n",
       "        [30267, 30268, 30025, 30025, 30025, 30025, 30026, 30026],\n",
       "        [30974, 30974, 30992, 31223, 31223, 31141, 31114, 31033],\n",
       "        [29880, 29853, 29853, 29854, 30190, 30163, 30163, 30244],\n",
       "        [29961, 29961, 29961, 29961, 29880, 29880, 29880, 29880],\n",
       "        [29880, 29880, 29880, 29880, 29880, 29880, 29881, 29881],\n",
       "        [29854, 30190, 30163, 30163, 30244, 30245, 30974, 30974],\n",
       "        [30432, 30432, 30432, 30189, 30270, 30267, 30267, 30268],\n",
       "        [29881, 29881, 29881, 29880, 29853, 29853, 29854, 30190],\n",
       "        [29880, 29880, 29880, 29881, 29881, 29881, 29881, 29880]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[:, -8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3ec5f49-585f-4a76-8671-092b47f88a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0144e+00,  3.4179e-01,  7.2654e-01,  3.9015e-01, -9.3770e-01,\n",
       "          -4.5149e-01, -7.6228e-01],\n",
       "         [ 2.0379e+00,  8.4566e-01,  9.0550e-02, -8.2488e-01, -1.2245e+00,\n",
       "          -6.4813e-01, -6.4755e-02],\n",
       "         [ 8.8245e-01,  8.7198e-02,  4.4365e-01, -2.2315e-01, -1.5250e+00,\n",
       "          -4.1966e-01, -4.1730e-01],\n",
       "         [ 1.3478e+00,  8.5450e-01,  1.0696e+00, -8.3486e-01, -1.7778e-01,\n",
       "          -2.8512e-01, -8.4387e-01],\n",
       "         [ 1.1205e+00,  1.0850e-01,  6.1234e-01, -1.0628e+00, -1.1799e+00,\n",
       "          -4.9026e-01, -5.8264e-01],\n",
       "         [ 1.3364e+00,  1.9319e+00,  1.2419e+00, -8.2427e-01, -9.5564e-02,\n",
       "          -8.9882e-01, -4.8563e-01],\n",
       "         [ 6.5008e-01,  1.5054e+00,  1.4593e+00, -1.1284e+00, -4.1123e-01,\n",
       "          -1.5325e-01, -4.8267e-01],\n",
       "         [ 9.0568e-01,  1.9906e+00,  1.4715e+00, -1.0812e+00,  3.9649e-04,\n",
       "          -3.5556e-01, -7.1115e-01]],\n",
       "\n",
       "        [[-1.3972e+00,  5.5643e-01, -9.5746e-01,  3.8262e-01, -8.7173e-01,\n",
       "          -3.8574e-01,  4.7621e-01],\n",
       "         [-5.6047e-01,  1.9633e-01, -1.5296e+00, -7.8944e-02, -9.6177e-01,\n",
       "          -2.0997e-01,  1.0995e+00],\n",
       "         [-1.1855e+00,  1.0973e-01, -8.5225e-01,  1.6100e-01, -7.4583e-01,\n",
       "          -9.3742e-01,  6.9915e-01],\n",
       "         [-5.4423e-01,  6.6443e-01, -1.2738e+00, -6.7833e-02, -3.7574e-01,\n",
       "          -3.2492e-01, -5.7841e-01],\n",
       "         [-1.1667e+00,  2.8356e-01, -1.6832e+00,  3.4011e-01, -9.6947e-01,\n",
       "          -4.9770e-01, -5.5209e-01],\n",
       "         [-4.4058e-01, -5.0579e-01, -1.0637e+00,  5.4880e-01, -3.9574e-01,\n",
       "          -5.2139e-01, -2.0701e-01],\n",
       "         [-6.9887e-01, -7.0929e-01, -8.7549e-01, -1.0661e-02, -9.1293e-01,\n",
       "          -4.9329e-02, -5.0756e-01],\n",
       "         [-7.9984e-01, -5.4851e-01, -8.1917e-01,  1.9620e-01, -2.2883e-01,\n",
       "          -5.0310e-02, -5.4499e-01]],\n",
       "\n",
       "        [[ 9.1325e-01,  5.1723e-01, -1.6128e-01,  4.8438e-01, -8.2418e-01,\n",
       "          -4.2197e-01, -5.3295e-01],\n",
       "         [ 1.8305e+00,  5.5784e-01, -5.3332e-02, -7.4046e-01, -1.1511e+00,\n",
       "          -3.0300e-01,  2.4176e-01],\n",
       "         [ 9.6141e-01,  2.8252e-01,  7.3431e-01, -1.4230e-01, -1.6141e+00,\n",
       "          -6.1707e-01, -3.6846e-01],\n",
       "         [ 1.3332e+00,  6.9280e-01,  8.8839e-01,  2.2739e-01, -1.1438e+00,\n",
       "           6.6498e-03, -8.2833e-01],\n",
       "         [ 8.0429e-01,  4.9359e-01,  5.5714e-01,  2.3485e-01, -2.2075e+00,\n",
       "          -5.0562e-01, -4.5380e-01],\n",
       "         [ 1.4346e+00,  9.5631e-01,  1.3264e+00,  5.9037e-01, -1.1884e+00,\n",
       "          -7.1927e-01, -3.1312e-01],\n",
       "         [ 5.9379e-01,  5.9931e-01,  1.3076e+00, -1.0108e+00, -4.8619e-01,\n",
       "          -9.8449e-02, -3.6603e-01],\n",
       "         [ 8.9768e-01,  7.7384e-01,  1.1983e+00, -1.0478e+00, -5.8874e-02,\n",
       "          -2.5164e-01, -6.9157e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
