{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579a490d-10c9-43a4-9e5a-36dc21d1ac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA L40S\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Restrict PyTorch to only see GPU 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU.\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfc1628-4a88-43ff-ad9b-4b2b97348037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-14 17:19:46.792487: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-14 17:19:46.822506: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-14 17:19:46.822551: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-14 17:19:46.823642: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-14 17:19:46.828980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-14 17:19:47.473096: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-14 17:19:49,347] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import wandb\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import logging\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import transformers\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup, get_scheduler\n",
    "from transformers.trainer import ALL_LAYERNORM_LAYERS, get_parameter_names\n",
    "from PIL import Image\n",
    "from accelerate import PartialState\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Dict, Optional, Sequence, List\n",
    "from torch.nn import MSELoss, L1Loss, SmoothL1Loss\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "from spatialvla.datasets import RLDSDataset, RLDSBatchTransform\n",
    "from spatialvla.datasets.rlds.utils.data_utils import save_dataset_statistics\n",
    "from spatialvla.datasets.rlds.utils.data_utils import PaddedCollatorForActionPrediction\n",
    "\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_pretrained_vlm_for_vla\n",
    "from spatialvla.mobilevlm.train.train import find_all_linear_names, get_peft_state_maybe_zero_3, get_peft_state_non_lora_maybe_zero_3, find_all_names_from_module\n",
    "\n",
    "from scripts.spatialvla_config import ModelArguments, TrainingArguments, HEAD_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902a3462-d082-478b-8b86-fcfd8fe7033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_args = ModelArguments()\n",
    "model_args.action_head = 'Diffusion'\n",
    "model_args.head_args = HEAD_ARGS['Diffusion']\n",
    "training_args = TrainingArguments()\n",
    "dtype = torch.bfloat16\n",
    "device_id = 0\n",
    "tokenizer, model, image_processor, _ = load_pretrained_vlm_for_vla(\n",
    "    model_args, \n",
    "    load_8bit=False, \n",
    "    load_4bit=False,\n",
    "    device=device_id,\n",
    "    dtype=dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e424c36d-8f43-4f2a-b917-68d890cdbbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.model.vision_tower.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce53f054-7192-4e2d-85ac-17cf15877606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters:\n",
      "\n",
      "Total Trainable Parameters: 1682552951\n"
     ]
    }
   ],
   "source": [
    "trainable_params = 0\n",
    "print(\"Trainable Parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        # print(f\"  {name}: {param.numel()} parameters\")\n",
    "        trainable_params += param.numel()\n",
    "print(f\"\\nTotal Trainable Parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e75617b0-46aa-4c3b-b6be-ae8b63032764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_vla, load_pretrained_model\n",
    "from spatialvla.mobilevlm.conversation import conv_templates, SeparatorStyle\n",
    "from spatialvla.mobilevlm.utils import disable_torch_init, process_images, tokenizer_image_token, KeywordsStoppingCriteria\n",
    "from spatialvla.mobilevlm.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, IGNORE_INDEX\n",
    "image = Image.open('lasagna.png')\n",
    "images = [image]\n",
    "images_tensor = process_images(images, image_processor, {'image_aspect_ratio' : 'pad'}).to(model.device, dtype=torch.bfloat16)\n",
    "conv = conv_templates['v1'].copy()\n",
    "conv.append_message(conv.roles[0], DEFAULT_IMAGE_TOKEN + \"\\n\" + 'How many layers it have?')\n",
    "conv.append_message(conv.roles[1], 'hello')\n",
    "prompt = conv.get_prompt()\n",
    "stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "# Input\n",
    "input_ids = (tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).cuda())\n",
    "labels = input_ids.clone()\n",
    "labels[:, :-5] = IGNORE_INDEX\n",
    "attention_mask = input_ids.ne(IGNORE_INDEX)\n",
    "stopping_criteria = KeywordsStoppingCriteria([stop_str],tokenizer, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "373a9bcb-c1f5-4922-b7e8-5ba94aac6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = None\n",
    "past_key_values = None\n",
    "inputs_embeds = None\n",
    "# labels = None\n",
    "use_cache = None\n",
    "output_attentions = False\n",
    "output_hidden_states = False\n",
    "return_dict = None\n",
    "actions = None\n",
    "output_attentions = output_attentions if output_attentions is not None else model.config.output_attentions\n",
    "output_hidden_states = (output_hidden_states if output_hidden_states is not None else model.config.output_hidden_states)\n",
    "return_dict = return_dict if return_dict is not None else model.config.use_return_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1155feef-eecf-4e64-b2f6-7170b218a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, past_key_values, inputs_embeds, labels = \\\n",
    "            model.prepare_inputs_labels_for_multimodal(input_ids, attention_mask, past_key_values, labels, images_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39d6f703-e579-411a-836f-27f888e81ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.model(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    past_key_values=past_key_values,\n",
    "    inputs_embeds=inputs_embeds,\n",
    "    use_cache=use_cache,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=output_hidden_states,\n",
    "    return_dict=return_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9833b101-f912-46d2-9359-bec747316075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 194, 2048])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e9f67-8881-49c5-9f86-a98b8edc4fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
