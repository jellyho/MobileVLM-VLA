{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579a490d-10c9-43a4-9e5a-36dc21d1ac4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA L40S\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Restrict PyTorch to only see GPU 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU.\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfc1628-4a88-43ff-ad9b-4b2b97348037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 18:08:55,338] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 18:08:55.651696: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-09 18:08:55.681034: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-09 18:08:55.681081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-09 18:08:55.681963: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-09 18:08:55.687311: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-09 18:08:56.378024: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_pretrained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902a3462-d082-478b-8b86-fcfd8fe7033e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jellyho/miniconda3/envs/mobilevlm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1142: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\"mtgv/MobileVLM-1.7B\", False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e75617b0-46aa-4c3b-b6be-ae8b63032764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from spatialvla.mobilevlm.model.mobilevlm import load_vla, load_pretrained_model\n",
    "from spatialvla.mobilevlm.conversation import conv_templates, SeparatorStyle\n",
    "from spatialvla.mobilevlm.utils import disable_torch_init, process_images, tokenizer_image_token, KeywordsStoppingCriteria\n",
    "from spatialvla.mobilevlm.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, IGNORE_INDEX\n",
    "image = Image.open('lasagna.png')\n",
    "images = [image]\n",
    "images_tensor = process_images(images, image_processor, {'image_aspect_ratio' : 'pad'}).to(model.device, dtype=torch.bfloat16)\n",
    "conv = conv_templates['v1'].copy()\n",
    "conv.append_message(conv.roles[0], DEFAULT_IMAGE_TOKEN + \"\\n\" + 'How many layers it have?')\n",
    "conv.append_message(conv.roles[1], 'hello')\n",
    "prompt = conv.get_prompt()\n",
    "stop_str = conv.sep if conv.sep_style != SeparatorStyle.TWO else conv.sep2\n",
    "# Input\n",
    "input_ids = (tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors=\"pt\").unsqueeze(0).cuda())\n",
    "labels = input_ids.clone()\n",
    "labels[:, :-5] = IGNORE_INDEX\n",
    "attention_mask = input_ids.ne(IGNORE_INDEX)\n",
    "stopping_criteria = KeywordsStoppingCriteria([stop_str],tokenizer, input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "373a9bcb-c1f5-4922-b7e8-5ba94aac6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = None\n",
    "past_key_values = None\n",
    "inputs_embeds = None\n",
    "# labels = None\n",
    "use_cache = None\n",
    "output_attentions = False\n",
    "output_hidden_states = False\n",
    "return_dict = None\n",
    "actions = None\n",
    "output_attentions = output_attentions if output_attentions is not None else model.config.output_attentions\n",
    "output_hidden_states = (output_hidden_states if output_hidden_states is not None else model.config.output_hidden_states)\n",
    "return_dict = return_dict if return_dict is not None else model.config.use_return_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1155feef-eecf-4e64-b2f6-7170b218a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, past_key_values, inputs_embeds, labels = \\\n",
    "            model.prepare_inputs_labels_for_multimodal(input_ids, attention_mask, past_key_values, labels, images_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39d6f703-e579-411a-836f-27f888e81ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.model(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    past_key_values=past_key_values,\n",
    "    inputs_embeds=inputs_embeds,\n",
    "    use_cache=use_cache,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=output_hidden_states,\n",
    "    return_dict=return_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9833b101-f912-46d2-9359-bec747316075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 194, 2048])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e9f67-8881-49c5-9f86-a98b8edc4fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
